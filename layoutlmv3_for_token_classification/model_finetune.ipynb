{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layoutlm V3 for Token Classification\n",
    "\n",
    "Huggingface Model Reference Link: \n",
    "1. https://huggingface.co/docs/transformers/model_doc/layoutlmv3\n",
    "2. https://huggingface.co/microsoft/layoutlmv3-base\n",
    "\n",
    "Model Paper: https://arxiv.org/pdf/2204.08387"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll start by importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "import json\n",
    "from datetime import date, datetime\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "from transformers import LayoutLMv3ForTokenClassification, LayoutLMv3Processor, LayoutLMv3Config\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current date and time\n",
    "dat = str(date.today())\n",
    "dat_tim = datetime.today().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "# Check if GPU is available\n",
    "gpu_available = torch.cuda.is_available()\n",
    "gpu_count = None\n",
    "gpu_variant = None\n",
    "\n",
    "if gpu_available:\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    gpu_variant = torch.cuda.get_device_name(0)\n",
    "    one_gpu_size = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    one_gpu_size = round(one_gpu_size, 2)\n",
    "\n",
    "# Get total RAM size and convert it to GB\n",
    "total_ram = psutil.virtual_memory().total\n",
    "total_ram_gb = round(total_ram / (1024 ** 3), 2)\n",
    "\n",
    "# Hardware specs dictionary\n",
    "hardware_specs = {\n",
    "    \"vm_ram_memory_gb\": total_ram_gb,\n",
    "    \"gpu_available\": gpu_available,\n",
    "    \"total_gpu_count\": gpu_count,\n",
    "    \"gpu_variant\": gpu_variant,\n",
    "    \"one_gpu_size_gb\": one_gpu_size if gpu_available else None\n",
    "}\n",
    "print(hardware_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the fine-tune count\n",
    "finetune_count = 9\n",
    "\n",
    "# Define paths for model and data\n",
    "processor_path = '/local/folder/path/where/model/is/stored'\n",
    "model_name = '/local/folder/path/where/model/is/stored'\n",
    "model_op_dir_path = f\"/output/directory/path/to/store/weights/file\"\n",
    "output_dir = model_op_dir_path\n",
    "os.makedirs(model_op_dir_path, exist_ok=True)\n",
    "\n",
    "# Define paths for data\n",
    "data_folder_path = \"/path/where/image/data/is/stored\"\n",
    "current_working_directory_path = \"/current/working/directory/path\"\n",
    "other_supporting_data_path = \"/path/of/json/file/\"\n",
    "\n",
    "image_folder = \"image_seperated_pdfs\"\n",
    "json_folder = \"page_seperated_json\"\n",
    "data_date_range = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class for storing metadata about training\n",
    "class TrainingMetadata:\n",
    "    def __init__(self, date, model_op_dir_path):\n",
    "        # Initialize variables related to training metadata\n",
    "        self.model_op_dir_path = model_op_dir_path\n",
    "        self.finetune_count = -1\n",
    "        self.model_name = \"\"\n",
    "        self.date = date\n",
    "        self.hardware_info = {}\n",
    "        self.dataset_load_start_time = None\n",
    "        self.dataset_load_end_time = None\n",
    "        self.dataset_load_time_required = None\n",
    "        self.batch_size = -1\n",
    "        self.validation_dataset_size = -1\n",
    "        self.dataset_rows = -1\n",
    "        self.total_dataset_samples = -1\n",
    "        self.failed_rows_samples = -1\n",
    "        self.total_train_samples = -1\n",
    "        self.total_val_samples = -1\n",
    "        self.total_fields = -1\n",
    "        self.fields_list = []\n",
    "        self.train_start_time = None\n",
    "        self.train_end_time = None\n",
    "        self.train_time_required = None\n",
    "        self.num_epochs = -1\n",
    "        self.patience = -1\n",
    "        self.default_learning_rate = None\n",
    "        self.optimizer = \"None\"\n",
    "        self.scheduler = \"None\"\n",
    "        self.dropout_rate = 0.3\n",
    "        self.hidden_dropout_prob = 0.3\n",
    "        self.attention_probs_dropout_prob = 0.3\n",
    "        self.dropout = 0.3\n",
    "        self.hidden_size = 512\n",
    "        self.visualizer_image_path = \"\"\n",
    "        self.tarining_flow = []\n",
    "        self.metrics_history = {}\n",
    "\n",
    "    def get_training_metadata(self):\n",
    "        return {key: getattr(self, key) for key in vars(self)}\n",
    "\n",
    "    def save_training_metadata(self):\n",
    "        # Save metadata to JSON file\n",
    "        os.makedirs(self.model_op_dir_path, exist_ok=True)\n",
    "        finetune_metadata_file_path = os.path.join(self.model_op_dir_path, \"finetune_metadata.json\")\n",
    "        finetune_metadata = self.get_training_metadata()\n",
    "        try:\n",
    "            with open(finetune_metadata_file_path, \"w\") as json_file:\n",
    "                json.dump(finetune_metadata, json_file, indent=3)\n",
    "        except Exception as e:\n",
    "            print(\"Exception in storing metadata json file.\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the metadata object\n",
    "training_metadata = TrainingMetadata(date=dat, model_op_dir_path=model_op_dir_path)\n",
    "training_metadata.finetune_count = finetune_count\n",
    "training_metadata.model_name = \"LayoutLM_V3_ForTokenClassification\"\n",
    "training_metadata.hardware_info = hardware_specs\n",
    "training_metadata.batch_size = 16\n",
    "training_metadata.validation_dataset_size = 0.25\n",
    "training_metadata.num_epochs = 22\n",
    "training_metadata.patience = 6\n",
    "training_metadata.default_learning_rate = 5e-5\n",
    "training_metadata.optimizer = \"AdamW\"\n",
    "training_metadata.scheduler = \"ReduceLROnPlateau\"\n",
    "training_metadata.hidden_dropout_prob = 0.3\n",
    "training_metadata.attention_probs_dropout_prob = 0.3\n",
    "training_metadata.dropout = 0.3\n",
    "\n",
    "# Save training metadata\n",
    "training_metadata.save_training_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class to plot traning metrics graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for visualizing training metrics\n",
    "class TrainingVisualizer:\n",
    "    def __init__(self, checkpoint_dir='model_checkpoints', training_metadata=None):\n",
    "        # Initialize tracking lists for various metrics\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.learning_rates = []\n",
    "        self.train_metrics = []\n",
    "        self.val_metrics = []\n",
    "        self.gradient_norms = []\n",
    "        self.weight_distributions = []\n",
    "\n",
    "        # Checkpoint directory\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        self.training_metadata = training_metadata\n",
    "\n",
    "    def plot_all_metrics(self):\n",
    "        \"\"\"\n",
    "        Create a comprehensive visualization of training metrics.\n",
    "        \"\"\"\n",
    "        # Create a figure with multiple subplots\n",
    "        plt.figure(figsize=(20, 15))\n",
    "        plt.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9, wspace=0.3, hspace=0.3)\n",
    "        \n",
    "        # Plot Loss Curves\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(self.train_losses, label='Training Loss')\n",
    "        plt.plot(self.val_losses, label='Validation Loss')\n",
    "        plt.title('Model Loss over Epochs')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # Plot Learning Rate Tracking\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(self.learning_rates)\n",
    "        plt.title('Learning Rate Schedule')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Learning Rate')\n",
    "\n",
    "        # Plot Loss and Performance Heatmap\n",
    "        plt.subplot(2, 2, 3)\n",
    "        metrics_df = pd.DataFrame({\n",
    "            'Epoch': range(1, len(self.train_losses) + 1),\n",
    "            'Train Loss': self.train_losses,\n",
    "            'Val Loss': self.val_losses,\n",
    "        })\n",
    "        metrics_corr = metrics_df.corr()\n",
    "        sns.heatmap(metrics_corr, annot=True, cmap='coolwarm', center=0)\n",
    "        plt.title('Correlation Between Training Metrics')\n",
    "\n",
    "        # Plot Gradient Norms\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.plot(self.gradient_norms)\n",
    "        plt.title('Gradient Norms')\n",
    "        plt.xlabel('Training Step')\n",
    "        plt.ylabel('Gradient Norm')\n",
    "\n",
    "        # Save the plot\n",
    "        img_name = f\"model_training_stats_{self.training_metadata.finetune_count}_{dat_tim}.png\"\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.checkpoint_dir, img_name))\n",
    "        plt.close()\n",
    "\n",
    "        return os.path.join(self.checkpoint_dir, img_name)\n",
    "\n",
    "    def log_metrics(self, model, epoch, train_loss, val_loss, learning_rate, avg_train_acc, avg_val_acc, additional_metric=None):\n",
    "        \"\"\"\n",
    "        Log training metrics for visualization\n",
    "        \n",
    "        Args:\n",
    "            model: PyTorch model\n",
    "            epoch: Current epoch number\n",
    "            train_loss: Training loss for the epoch\n",
    "            val_loss: Validation loss for the epoch\n",
    "            learning_rate: Current learning rate\n",
    "            additional_metric: Optional performance metric\n",
    "        \"\"\"\n",
    "        # Log losses\n",
    "        self.train_losses.append(train_loss)\n",
    "        self.val_losses.append(val_loss)\n",
    "        \n",
    "        # Log learning rate\n",
    "        self.learning_rates.append(learning_rate)\n",
    "        \n",
    "        # Optional additional metric\n",
    "        if additional_metric is not None:\n",
    "            self.train_metrics.append(additional_metric)\n",
    "        \n",
    "        # Track gradient norms\n",
    "        total_grad_norm = 0\n",
    "        for param in model.parameters():\n",
    "            if param.grad is not None:\n",
    "                param_grad_norm = param.grad.detach().data.norm(2).item()\n",
    "                total_grad_norm += param_grad_norm\n",
    "        self.gradient_norms.append(total_grad_norm)\n",
    "        \n",
    "        # Track weight distributions\n",
    "        weights = []\n",
    "        for param in model.parameters():\n",
    "            weights.extend(param.data.cpu().numpy().flatten())\n",
    "        self.weight_distributions.extend(weights)\n",
    "        \n",
    "    def plot_all_metrics_in_one_image(self, metrics_history):\n",
    "        \"\"\"\n",
    "        Plots all important graphs in a single image and saves it as a PNG file.\n",
    "\n",
    "        Args:\n",
    "            metrics_history (dict): Dictionary containing training and validation metrics.\n",
    "            output_dir (str): Directory to save the plot.\n",
    "        \"\"\"\n",
    "        # # Create output directory if it doesn't exist\n",
    "        # os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Create a figure with subplots\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(20, 18))\n",
    "        fig.suptitle('Training and Validation Metrics', fontsize=16)\n",
    "\n",
    "        # Plot Training and Validation Loss\n",
    "        axes[0, 0].plot(metrics_history['train_loss'], label='Train Loss')\n",
    "        axes[0, 0].plot(metrics_history['val_loss'], label='Validation Loss')\n",
    "        axes[0, 0].set_title('Training and Validation Loss')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True)\n",
    "\n",
    "        # Plot Training and Validation Accuracy\n",
    "        axes[0, 1].plot(metrics_history['train_accuracy'], label='Train Accuracy')\n",
    "        axes[0, 1].plot(metrics_history['val_accuracy'], label='Validation Accuracy')\n",
    "        axes[0, 1].set_title('Training and Validation Accuracy')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('Accuracy')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True)\n",
    "\n",
    "        # Plot Training Precision, Recall, and F1\n",
    "        axes[1, 0].plot(metrics_history['train_precision'], label='Train Precision')\n",
    "        axes[1, 0].plot(metrics_history['train_recall'], label='Train Recall')\n",
    "        axes[1, 0].plot(metrics_history['train_f1'], label='Train F1')\n",
    "        axes[1, 0].set_title('Training Precision, Recall, and F1')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Score')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True)\n",
    "\n",
    "        # Plot Validation Precision, Recall, and F1\n",
    "        axes[1, 1].plot(metrics_history['val_precision'], label='Validation Precision')\n",
    "        axes[1, 1].plot(metrics_history['val_recall'], label='Validation Recall')\n",
    "        axes[1, 1].plot(metrics_history['val_f1'], label='Validation F1')\n",
    "        axes[1, 1].set_title('Validation Precision, Recall, and F1')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Score')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True)\n",
    "\n",
    "        # Plot Gradients (Average Gradient Norm per Epoch)\n",
    "        if 'gradients' in metrics_history:\n",
    "            avg_grad_norms = []\n",
    "            for epoch_grads in metrics_history['gradients']:\n",
    "                avg_grad_norm = sum(grad[1] for grad in epoch_grads) / len(epoch_grads)\n",
    "                avg_grad_norms.append(avg_grad_norm)\n",
    "\n",
    "            axes[2, 0].plot(avg_grad_norms, label='Average Gradient Norm')\n",
    "            axes[2, 0].set_title('Average Gradient Norm per Epoch')\n",
    "            axes[2, 0].set_xlabel('Epoch')\n",
    "            axes[2, 0].set_ylabel('Gradient Norm')\n",
    "            axes[2, 0].legend()\n",
    "            axes[2, 0].grid(True)\n",
    "\n",
    "        # Plot Activations (Average Activation Magnitude per Epoch)\n",
    "        if 'activations' in metrics_history:\n",
    "            avg_activation_magnitudes = [np.mean(np.abs(act)) for act in metrics_history['activations']]\n",
    "\n",
    "            axes[2, 1].plot(avg_activation_magnitudes, label='Average Activation Magnitude')\n",
    "            axes[2, 1].set_title('Average Activation Magnitude per Epoch')\n",
    "            axes[2, 1].set_xlabel('Epoch')\n",
    "            axes[2, 1].set_ylabel('Activation Magnitude')\n",
    "            axes[2, 1].legend()\n",
    "            axes[2, 1].grid(True)\n",
    "        \n",
    "        img_name = f\"all_metrics_plot_{self.training_metadata.finetune_count}_{dat_tim}.png\"\n",
    "        img_path = os.path.join(self.checkpoint_dir, img_name)\n",
    "        \n",
    "        # Adjust layout and save the figure\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to prevent overlap\n",
    "        plt.savefig(img_path)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"All metrics plot saved to {img_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset class for Named Entity Recognition (NER)\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, data, processor, labels_map):\n",
    "        self.data = data\n",
    "        self.processor = processor\n",
    "        self.labels_map = labels_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        file_date = item[\"date\"]\n",
    "        img_name = item['page_file_name']\n",
    "        img_base_path = os.path.join(data_folder_path, f\"{file_date}/{image_folder}/{img_name}.png\")\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_base_path).convert(\"RGB\")\n",
    "\n",
    "        # Helper function to encode word labels\n",
    "        def encode_word_labels(word_labels):\n",
    "            int_labels = [0] * len(word_labels)\n",
    "            for i in range(len(word_labels)):\n",
    "                int_labels[i] = self.labels_map[\"fields_to_label\"][str(word_labels[i])]\n",
    "            return int_labels\n",
    "        \n",
    "        max_len = 512\n",
    "        # Encode word string labels to integer labels\n",
    "        int_labels = encode_word_labels(item['words_labels'])\n",
    "\n",
    "        # Prepare inputs using the processor\n",
    "        inputs = self.processor(\n",
    "            image, \n",
    "            item['words'], \n",
    "            boxes=item['page_words_bboxes_normalized'], \n",
    "            word_labels=int_labels,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_len\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'bbox': inputs['bbox'].squeeze(),\n",
    "            'labels': inputs['labels'].squeeze(),\n",
    "            'pixel_values': inputs['pixel_values'].squeeze(),\n",
    "            'int_labels': int_labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cusstom Model Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_train_loop(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    processor,\n",
    "    device, \n",
    "    epochs, \n",
    "    learning_rate, \n",
    "    patience, \n",
    "    class_weights=None,\n",
    "    visualizer=None,\n",
    "    training_metadata=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Custom training loop for training a model with train and validation data.\n",
    "    Includes metrics tracking, learning rate scheduling, and model checkpointing.\n",
    "    \"\"\"\n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=patience, verbose=True)\n",
    "    \n",
    "    # Initialize loss function (Cross Entropy)\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    # Tracking variables for best model\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Metrics history\n",
    "    metrics_history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_accuracy': [],\n",
    "        'val_accuracy': [],\n",
    "        'train_precision': [],\n",
    "        'train_recall': [],\n",
    "        'train_f1': [],\n",
    "        'val_precision': [],\n",
    "        'val_recall': [],\n",
    "        'val_f1': [],\n",
    "        'gradients': [],\n",
    "        'class_weights': class_weights.tolist() if class_weights is not None else None,\n",
    "        'activations': []\n",
    "    }\n",
    "    \n",
    "    def compute_metrics(predictions, labels):\n",
    "        \"\"\"\n",
    "        Compute precision, recall, F1 score, and accuracy from predictions and true labels.\n",
    "        \"\"\"\n",
    "        active_predictions = predictions.flatten()[labels.flatten() != -100]\n",
    "        active_labels = labels.flatten()[labels.flatten() != -100]\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(active_labels.cpu(), active_predictions.cpu(), average='weighted', zero_division=0)\n",
    "        accuracy = accuracy_score(active_labels.cpu(), active_predictions.cpu())\n",
    "        return precision, recall, f1, accuracy\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        total_train_loss, total_train_acc, train_batches = 0, 0, 0\n",
    "        \n",
    "        print(f\"\\nTraining epoch: {epoch+1}\")\n",
    "        \n",
    "        # Training phase\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, bbox, labels, pixel_values = [batch[key].to(device) for key in ['input_ids', 'attention_mask', 'bbox', 'labels', 'pixel_values']]\n",
    "\n",
    "            optimizer.zero_grad()  # Zero gradients\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, labels=labels, pixel_values=pixel_values)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            predictions = logits.argmax(dim=-1)\n",
    "            precision, recall, f1, accuracy = compute_metrics(predictions, labels)\n",
    "            total_train_acc += accuracy\n",
    "            train_batches += 1\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            gradients = [(name, param.grad.norm().item()) for name, param in model.named_parameters() if param.grad is not None]\n",
    "            metrics_history['gradients'].append(gradients)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        total_val_loss, total_val_acc, val_batches = 0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids, attention_mask, bbox, labels, pixel_values = [batch[key].to(device) for key in ['input_ids', 'attention_mask', 'bbox', 'labels', 'pixel_values']]\n",
    "                \n",
    "                outputs = model(input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, labels=labels, pixel_values=pixel_values)\n",
    "                total_val_loss += outputs.loss.item()\n",
    "\n",
    "                # Compute validation accuracy\n",
    "                predictions = outputs.logits.argmax(dim=-1)\n",
    "                all_preds.append(predictions)\n",
    "                all_labels.append(labels)\n",
    "\n",
    "                precision, recall, f1, accuracy = compute_metrics(predictions, labels)\n",
    "                total_val_acc += accuracy\n",
    "                val_batches += 1\n",
    "\n",
    "        # Average losses and accuracies\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        avg_train_acc = total_train_acc / train_batches\n",
    "        avg_val_acc = total_val_acc / val_batches\n",
    "\n",
    "        # Compute precision, recall, and F1 for validation\n",
    "        all_preds = torch.cat(all_preds).flatten().cpu()\n",
    "        all_labels = torch.cat(all_labels).flatten().cpu()\n",
    "        val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "        # Log metrics\n",
    "        metrics_history['train_loss'].append(avg_train_loss)\n",
    "        metrics_history['val_loss'].append(avg_val_loss)\n",
    "        metrics_history['train_accuracy'].append(avg_train_acc)\n",
    "        metrics_history['val_accuracy'].append(avg_val_acc)\n",
    "        metrics_history['train_precision'].append(precision)\n",
    "        metrics_history['train_recall'].append(recall)\n",
    "        metrics_history['train_f1'].append(f1)\n",
    "        metrics_history['val_precision'].append(val_precision)\n",
    "        metrics_history['val_recall'].append(val_recall)\n",
    "        metrics_history['val_f1'].append(val_f1)\n",
    "\n",
    "        # Log activations (model output logits)\n",
    "        metrics_history['activations'].append(logits.detach().cpu().numpy())\n",
    "\n",
    "        # Current learning rate\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Log metrics for visualization\n",
    "        visualizer.log_metrics(model, epoch, avg_train_loss, avg_val_loss, current_lr, avg_train_acc, avg_val_acc)\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"Train Accuracy: {avg_train_acc:.4f}, Validation Accuracy: {avg_val_acc:.4f}\")\n",
    "        print(f\"Train Precision: {precision:.4f}, Train Recall: {recall:.4f}, Train F1: {f1:.4f}\")\n",
    "        print(f\"Validation Precision: {val_precision:.4f}, Validation Recall: {val_recall:.4f}, Validation F1: {val_f1:.4f}\")\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Model checkpointing and early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            # Save best model checkpoint\n",
    "            if epoch > 8 and (epoch % 2 == 0 or epoch % 3 == 0 or epoch % 5 == 0):\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                model.save_pretrained(os.path.join(output_dir, f'checkpoint-epoch-{epoch+1}'))\n",
    "                print(f\"Saved new best model at epoch {epoch+1} with validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # Early stopping (if no improvement for patience epochs)\n",
    "        if epochs_no_improve >= patience * 2:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "        # Store metadata for training\n",
    "        training_metadata.training_flow.append({\n",
    "            \"epoch_count\": epoch+1,\n",
    "            \"avg_train_loss\": avg_train_loss,\n",
    "            \"avg_val_loss\": avg_val_loss,\n",
    "            \"best_val_loss\": round(best_val_loss, 4),\n",
    "            \"current_lr\": current_lr,\n",
    "            \"train_accuracy\": round(avg_train_acc * 100, 2),\n",
    "            \"val_accuracy\": round(avg_val_acc * 100, 2)\n",
    "        })\n",
    "\n",
    "    print(f\"\\nTraining complete at epoch {epoch+1}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model.save_pretrained(os.path.join(output_dir, f'checkpoint-epoch-{epoch+1}'))\n",
    "    print(f\"Saved best model at epoch {epoch+1} with validation loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    # Save model state\n",
    "    try:\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, f'best_model_epoch_{epoch}.pth'))\n",
    "    except Exception as e:\n",
    "        print(\"Exception in saving model:\", e)\n",
    "\n",
    "    return best_model_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device is set to:\", device)\n",
    "\n",
    "\n",
    "# Training and data preparation code...\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device is set to: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = None\n",
    "field_and_labels_mapping_file_path = os.path.join(other_supporting_data_path, f\"field_and_labels_mappings_{data_date_range}.json\")\n",
    "with open (field_and_labels_mapping_file_path, 'r') as f:\n",
    "    label_map = json.load(f)\n",
    "    \n",
    "    \n",
    "training_metadata.total_fields = int(len(label_map[\"unique_fields\"]))\n",
    "training_metadata.fields_list = label_map[\"unique_fields\"]\n",
    "print(training_metadata.total_fields, training_metadata.fields_list)\n",
    "training_metadata.save_training_metadata()\n",
    "\n",
    "training_metadata.dataset_load_start_time = datetime.today().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "start_time =  datetime.today()\n",
    "\n",
    "data_list = None\n",
    "single_page_json_file_data_path = os.path.join(other_supporting_data_path, f\"single_page_files_list_train_3.json\")\n",
    "\n",
    "#Write dictionary to JSON file\n",
    "with open (single_page_json_file_data_path, 'r') as f:\n",
    "    data_list = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list_val = None\n",
    "# single_page_json_file_data_path = os.path.join(other_supporting_data_path, f\"single_page_files_list_val_2.json\")\n",
    "\n",
    "# #Write dictionary to JSON file\n",
    "# with open (single_page_json_file_data_path, 'r') as f:\n",
    "#     data_list_val = json.load(f)\n",
    "\n",
    "training_metadata.dataset_rows = int(len(data_list))\n",
    "\n",
    "print(\"training data sample rows: \", training_metadata.dataset_rows)\n",
    "print(\"row keys: \", data_list[0].keys())\n",
    "\n",
    "# print(\"training data sample rows: \", training_metadata.dataset_rows)\n",
    "# print(\"val len: \", len(data_list_val))\n",
    "\n",
    "# Initialize processor\n",
    "processor = LayoutLMv3Processor.from_pretrained(processor_path, apply_ocr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = True\n",
    "batch_size = training_metadata.batch_size\n",
    "\n",
    "dataset = NERDataset(data_list, processor, label_map)\n",
    "# dataset_val = NERDataset(data_list_val, processor, label_map)\n",
    "\n",
    "labels_lst = []\n",
    "datasetlst = []\n",
    "failed_files = []\n",
    "\n",
    "data_samples_len = len(data_list)\n",
    "# data_samples_len = 50\n",
    "for i in range(data_samples_len):\n",
    "    try:\n",
    "        item = dataset.__getitem__(i)\n",
    "        \n",
    "        if list(item.keys()) == list(['input_ids', 'attention_mask', 'bbox', 'labels', 'pixel_values', 'int_labels']):\n",
    "            labels_lst.append(item[\"int_labels\"])\n",
    "            del item[\"int_labels\"]\n",
    "            datasetlst.append(item)\n",
    "        \n",
    "    except Exception as e:\n",
    "        data_list[i]['enception'] = e\n",
    "        failed_files.append(data_list[i])\n",
    "\n",
    "training_metadata.total_dataset_samples = int(len(datasetlst))\n",
    "training_metadata.failed_rows_samples = int(len(failed_files))\n",
    "\n",
    "print(\"Total dataset samples for training: \",training_metadata.total_dataset_samples)\n",
    "print(\"Total dataset failed: \",training_metadata.failed_rows_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_size = 0.25\n",
    "print(\"train_test_split\")\n",
    "train_subset, val_subset = train_test_split(\n",
    "    datasetlst, \n",
    "    test_size=training_metadata.validation_dataset_size, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# train_subset = datasetlst\n",
    "# val_subset = datasetlst_val\n",
    "\n",
    "print(\"train loader\")\n",
    "train_dataloader = DataLoader(\n",
    "    train_subset, \n",
    "    batch_size=training_metadata.batch_size, \n",
    "    shuffle=shuffle\n",
    ")\n",
    "\n",
    "print(\"val loader\")\n",
    "val_dataloader = DataLoader(\n",
    "    val_subset, \n",
    "    batch_size=training_metadata.batch_size, \n",
    "    shuffle=shuffle\n",
    ")\n",
    "\n",
    "training_metadata.dataset_load_end_time = datetime.today().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "end_time = datetime.today()\n",
    "\n",
    "# Calculate the time difference\n",
    "time_difference = end_time - start_time\n",
    "\n",
    "time_difference_minutes = time_difference.total_seconds() / 60\n",
    "\n",
    "training_metadata.dataset_load_time_required = round(time_difference_minutes,3)\n",
    "\n",
    "training_metadata.total_train_samples = int(len(train_subset))\n",
    "training_metadata.total_val_samples = int(len(val_subset))\n",
    "\n",
    "training_metadata.save_training_metadata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "labels = np.concatenate(labels_lst)  # Flatten all labels\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "print(\"class weights: \", class_weights)\n",
    "\n",
    "config = LayoutLMv3Config.from_pretrained(model_name)\n",
    "\n",
    "config.num_labels = training_metadata.total_fields\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify dropout rates\n",
    "config.hidden_dropout_prob = training_metadata.hidden_dropout_prob      # Dropout for hidden states\n",
    "config.attention_probs_dropout_prob = training_metadata.attention_probs_dropout_prob  # Dropout for attention probabilities\n",
    "config.dropout = training_metadata.dropout_rate     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LayoutLMv3ForTokenClassification.from_pretrained(\n",
    "    model_name, \n",
    "    config = config\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "print(\"Model Device is set to:\", model.device)\n",
    "\n",
    "# Initialize visualizer\n",
    "visualizer = TrainingVisualizer(checkpoint_dir = model_op_dir_path, training_metadata = training_metadata)\n",
    "\n",
    "training_metadata.train_start_time = datetime.today().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "start_time = datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model training\n",
    "best_model_state = custom_train_loop(\n",
    "    model=model,\n",
    "    train_loader=train_dataloader,\n",
    "    val_loader=val_dataloader,\n",
    "    processor=processor,\n",
    "    device=device,\n",
    "    epochs=training_metadata.num_epochs,\n",
    "    learning_rate=training_metadata.default_learning_rate,\n",
    "    patience=training_metadata.patience,\n",
    "    class_weights=class_weights,\n",
    "    visualizer=visualizer,\n",
    "    training_metadata=training_metadata\n",
    ")\n",
    "\n",
    "# Save final metadata\n",
    "training_metadata.train_end_time = datetime.today().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "end_time = datetime.today()\n",
    "training_metadata.train_time_required = round((end_time - start_time).total_seconds() / 60, 3)\n",
    "training_metadata.visualizer_image_path = visualizer.plot_all_metrics()\n",
    "visualizer.plot_all_metrics_in_one_image(training_metadata.metrics_history)\n",
    "training_metadata.save_training_metadata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### inference\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import LayoutLMv3ForTokenClassification, LayoutLMv3Processor\n",
    "\n",
    "# Define paths\n",
    "processor_model_name = '/home/jovyan/work/Sagar/layoutlmv3_base'\n",
    "model_name = \"/home/jovyan/work/Sagar/layoutlmv3_kvp_playground/layoutlmv3_kvp_fine_tuned/finetune_6_2025-01-16/checkpoint-epoch-20\"\n",
    "data_folder_path = \"/home/jovyan/work/Sagar/p2p_august_5_to_11_data\"\n",
    "other_supporting_data_path = \"/home/jovyan/work/Sagar/p2p_august_5_to_11_data/other_supporting_data\"\n",
    "image_folder = \"image_seperated_pdfs\"\n",
    "data_date_range = \"5_to_11_august\"\n",
    "\n",
    "# Define dataset class\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, data, processor, labels_map):\n",
    "        self.data = data\n",
    "        self.processor = processor\n",
    "        self.labels_map = labels_map\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img_path = os.path.join(data_folder_path, f\"{item['date']}/{image_folder}/{item['page_file_name']}.png\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Encode labels\n",
    "        def encode_labels(word_labels):\n",
    "            return [self.labels_map[\"fields_to_label\"].get(str(lbl), 0) for lbl in word_labels]\n",
    "        \n",
    "        words = [re.sub(r'[^A-Za-z0-9 ]+', '', w).lower() for w in item['words']]\n",
    "        int_labels = encode_labels(item['words_labels'])\n",
    "        \n",
    "        # Process inputs\n",
    "        inputs = self.processor(\n",
    "            image, words, boxes=item['page_words_bboxes_normalized'],\n",
    "            return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"encodings\": {k: v.squeeze() for k, v in inputs.items()},\n",
    "            \"image\": img_path,\n",
    "            \"words\": item['words'],\n",
    "            \"words_bboxes\": item['page_words_bboxes_normalized'],\n",
    "            \"int_labels\": int_labels,\n",
    "            \"field_create\": item[\"field_create\"]\n",
    "        }\n",
    "\n",
    "# Load data\n",
    "with open(os.path.join(other_supporting_data_path, \"single_page_files_list_test_3.json\"), 'r') as f:\n",
    "    data_list = json.load(f)\n",
    "\n",
    "with open(os.path.join(other_supporting_data_path, f\"field_and_labels_mappings_{data_date_range}.json\"), 'r') as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "# Initialize processor and model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "processor = LayoutLMv3Processor.from_pretrained(processor_model_name, apply_ocr=False)\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint_path = os.path.join(model_name, \"best_model_epoch_19.pth\")\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "# Create dataset\n",
    "dataset = NERDataset(data_list, processor, label_map)\n",
    "\n",
    "# Inference function\n",
    "def inference(item, model, processor, device=device):\n",
    "    model.eval()\n",
    "    inputs = {k: v.to(device) for k, v in item[\"encodings\"].items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    predictions = outputs.logits.argmax(-1).squeeze().tolist()\n",
    "    extracted_fields = {}\n",
    "    for i, word in enumerate(item[\"words\"]):\n",
    "        label_id = predictions[i]\n",
    "        if label_id != 0:\n",
    "            field = label_map[\"label_to_field\"].get(str(label_id), \"Unknown\")\n",
    "            extracted_fields[field] = extracted_fields.get(field, \"\") + \" \" + word\n",
    "    \n",
    "    return {\n",
    "        \"image\": item[\"image\"],\n",
    "        \"predictions\": extracted_fields,\n",
    "        \"actual\": item[\"field_create\"]\n",
    "    }\n",
    "\n",
    "# Run inference on first item\n",
    "y = inference(dataset[0], model, processor)\n",
    "print(\"Actual:\", y[\"actual\"])\n",
    "print(\"Predictions:\", y[\"predictions\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
